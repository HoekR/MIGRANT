{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bak naar image naar kaart naar elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bak naar image naar kaart naar elasticsearch\n",
    "\n",
    "Converteer excel-files met beschrijving van de kaartenbakken naar imagename en expand images naar kaarten per (emigranten)\n",
    "unit. Indexeer vervolgens met de unit als parent naar elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## excel naar csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from operator import itemgetter\n",
    "import xlrd\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "# read excel files and convert only the first worksheet to csv (adapted from example on the Internet)\n",
    "\n",
    "def csv_from_excel(excel_file, outdir):\n",
    "    workbook = xlrd.open_workbook(excel_file)\n",
    "    all_worksheets = workbook.sheet_names()\n",
    "    worksheet_name = all_worksheets[0]\n",
    "    worksheet = workbook.sheet_by_name(worksheet_name)\n",
    "    nm = os.path.basename(excel_file)\n",
    "    nm = os.path.splitext(nm)[0]\n",
    "    out = os.path.join(outdir, nm + '_' + worksheet_name +'.csv')\n",
    "    print out\n",
    "    try:\n",
    "        os.makedirs(outdir)\n",
    "    except OSError:\n",
    "        pass\n",
    "    your_csv_file = open(out, 'wb')\n",
    "    wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)\n",
    "    for rownum in xrange(worksheet.nrows):\n",
    "        wr.writerow([unicode(entry).encode(\"utf-8\") for entry in worksheet.row_values(rownum)])\n",
    "    print \"converted %s\" % excel_file\n",
    "    your_csv_file.close()\n",
    "\n",
    "# help function to get drawer number from drawer description. Later on replaced with bak from imagename\n",
    "def bak2nr(flin='/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/bakken.csv'):\n",
    "    flin = open(flin)\n",
    "    r = csv.DictReader(flin)\n",
    "    lst = {row['archieflink']: int(row['nr']) for row in r}\n",
    "    return lst\n",
    "\n",
    "# expand number of images per unit to cover alle images in  drawer (as far as described in excel file)\n",
    "def relpers2scan(fl):\n",
    "    \"\"\"link person identifier to scans numbers\n",
    "    example of flin: /home/rik/Dropbox/Link to emigrantenkaarten/bak_nw_south_wales_bew.csv\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    flin = open(fl)\n",
    "    logger.info(\"converting %s\" % flin)\n",
    "    reader = csv.DictReader(flin)\n",
    "    baknrs = bak2nr()\n",
    "    scans = {}\n",
    "    #files are supposed to have at least the following fields\n",
    "    if not set(['imagenr', 'prs_uuid','aant','kaartenbak']) < set(reader.fieldnames): \n",
    "        logging.debug(\"FILE DOES NOT HAVE THE RIGHT FIELDS\") # mark for postprocessing\n",
    "        raise ValueError\n",
    "               \n",
    "    else:\n",
    "        archieflink = re.search('bak([0-9]+)', fl).groups()[0]\n",
    "        for i in reader:\n",
    "            if i['imagenr'] != '' and i['imagenr'][0] in string.digits:\n",
    "#                if i['archieflink'] in baknrs.keys():\n",
    "#                    nr = baknrs[i['archieflink']]\n",
    "                    \n",
    "                i['archieflink'] = archieflink\n",
    "                scans[int(i['imagenr'].split('.')[0])] = [i['prs_uuid'], i['aant'],i['archieflink']]\n",
    "#        scans.sort(key=itemgetter(0))\n",
    "        lst = scans.keys()\n",
    "        mn = min(lst)\n",
    "        mx = max(lst)\n",
    "        scanlist = range(mn,mx + 2)\n",
    "        nwscans = []\n",
    "        curscan = scans[mn]\n",
    "        for i in scanlist:\n",
    "            if i in lst:\n",
    "                curscan = scans[i]    \n",
    "            result = [i]\n",
    "            result.extend(curscan)\n",
    "            nwscans.append(result)               \n",
    "        return nwscans    \n",
    "\n",
    "#convert original csv to csv with limited files for all images in drawer\n",
    "def kaart2image(f, outdir):\n",
    "    fl = os.path.basename(f)\n",
    "    fl = os.path.splitext(fl)[0]\n",
    "    flin = fl + '.csv'\n",
    "    fli = os.path.join(outdir, flin)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"infile: %s\" % f)\n",
    "    try:\n",
    "        nf = relpers2scan(f)\n",
    "        flout = os.path.join(outdir, fl+'_out.csv')\n",
    "        flt = open(flout, 'wb')\n",
    "        w = csv.writer(flt)\n",
    "        w.writerow(['image', 'kaart', 'aantekening', 'bak'])\n",
    "        w.writerows(nf)\n",
    "        flt.close()\n",
    "        logger.info(\"written: %s\" % flt)\n",
    "    except (ValueError, IndexError, TypeError):\n",
    "        pass # dangerous!\n",
    "\n",
    "#actual conversion. First step - convert excel to csv\n",
    "def convert(indir):\n",
    "    import glob, os, logging\n",
    "    logger = logging.getLogger()\n",
    "    fhandler = logging.FileHandler(filename='/Users/rikhoekstra/Documents/bak2image.log', mode='w')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    fls = glob.glob(indir + '*.xlsx')\n",
    "    outdir = os.path.join(indir, 'csv')\n",
    "    logging.info(outdir)\n",
    "    for fl in fls:\n",
    "        csv_from_excel(fl, outdir)\n",
    "    return 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's do this on the input directory given below. The function will emit all converted file names\n",
    "indir = \"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/\"\n",
    "convert(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and perform step 2 to expand images. \n",
    "# Remember to check the logs for files with faulty field names. These must be remedied by hand\n",
    "\n",
    "import glob, os, logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='/Users/rikhoekstra/Documents/bak2image.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "outdir = os.path.join(indir, 'csv')\n",
    "nfls = glob.glob(os.path.join(outdir, '*.csv'))\n",
    "for f in nfls:\n",
    "        kaart2image(f, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now import the image files into Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to import the necessary libraries and initiate an Elasticsearch object.\n",
    "import unicodecsv\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import RequestError\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "\n",
    "es = Elasticsearch(timeout=30, max_retries=10, retry_on_timeout=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping in index (the index should already exist)\n",
    "index = 'test_migrant'\n",
    "\n",
    "request_body = {   \n",
    "            \"image\": {\n",
    "                    \"_parent\": {\"type\": \"unit\"},\n",
    "                    \"properties\":{\n",
    "                        'image_id': {\"type\":\"string\"},\n",
    "                        'aantekening':{\"type\":\"text\"},\n",
    "                        'edges': {\"type\":\"integer\"},\n",
    "                        'ocr': {u'type': u'text'},\n",
    "                        'locr': {u'type':u'integer'}\n",
    "                    }\n",
    "                },\n",
    "    }\n",
    "\n",
    "INDEX_NAME=index\n",
    "es.indices.put_mapping(index = index, doc_type=\"image\",  body = request_body)\n",
    "    \n",
    "# check mapping\n",
    "es.indices.get_mapping(index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and now for some name manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get edges and ocr for images helping functions\n",
    "edgefile = \"/Users/rikhoekstra/surfdrive/emigratie/alledges.csv\"\n",
    "ocrdir = \"/Users/rikhoekstra/surfdrive/Shared/Database_Migrant/OCR_bakken/media/rutger/encrypted/emigratieregistratie\"\n",
    "flin = open(edgefile)\n",
    "r = csv.DictReader(flin)\n",
    "rows = [row for row in r]\n",
    "def getedges(im, rows=rows, ocrdir=ocrdir):\n",
    "    ocrdir = ocrdir\n",
    "    result = {}\n",
    "    edge = [d['edges'] for d in rows if d['file'] == im][0]\n",
    "    result['edge'] = edge\n",
    "    bak = \"{:02d}\".format(int(im.split('_')[2]))\n",
    "    imname = os.path.join(ocrdir, bak, im+'.txt')\n",
    "    flin = open(imname)\n",
    "    ocr = flin.read()\n",
    "    flin.close()\n",
    "    result['ocr'] = ocr\n",
    "    result['locr'] = len(ocr)\n",
    "    return result\n",
    "    \n",
    "# test (but don't expect too much from the ocr)\n",
    "getedges(\"NL-HaNA_2.05.159_8_0008.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://migrantcards.huygens.knaw.nl/cards\"\n",
    "\n",
    "urltemplate = \"{url}/{map:02d}/NL-HaNA_2.05.159_{map}_{imnr:04d}.jpg\"\n",
    "imagetemplate = \"NL-HaNA_2.05.159_{map}_{imnr:04d}.jpg\"\n",
    "\n",
    "#test \n",
    "print(urltemplate.format(url=url, map=8, imnr=8))\n",
    "print(imagetemplate.format(map=8, imnr=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get edges and ocr from other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodecsv import DictReader\n",
    "imfls = [fl for fl in imfls if fl not in outfls]\n",
    "faulty_items = []\n",
    "for fn in imfls:\n",
    "    try:\n",
    "        flin = open(fn)\n",
    "        r = DictReader(flin)\n",
    "        ims = [row for row in r]\n",
    "        for row in ims:\n",
    "            row['parent'] = row['kaart']\n",
    "            row['aantekening'] = row['aantekening']\n",
    "            edocr = getedges(imagetemplate.format( map=int(row['bak']), imnr=int(row[\"image\"])))\n",
    "            row['id'] = \"{map}_{imnr:04d}\".format(map=row['bak'], imnr=int(row['image']))\n",
    "            row['url'] = urltemplate.format(url=url, map=int(row['bak']), imnr=int(row[\"image\"]))\n",
    "            row['edges'] = int(edocr['edge'])\n",
    "            row['locr'] = int(edocr['locr'])\n",
    "            row['ocr'] = dammit(edocr['ocr']).unicode_markup\n",
    "        \n",
    "    except IndexError, KeyError:\n",
    "        faulty_items.append(row)\n",
    "    data_dict = ims\n",
    "    bulk_data = []\n",
    "    for item in data_dict:\n",
    "        try:\n",
    "            bulk_data.append({'index':{'_type':'image', \n",
    "                                       '_index':index,\n",
    "                                       'parent': item['parent'],\n",
    "                                       '_id':'%s' % item.get('id')}})\n",
    "            bulk_data.append(item)\n",
    "        except KeyError:\n",
    "            print fn\n",
    "            print item\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imfls = glob.glob(os.path.join(outdir, '*_out.csv'))\n",
    "outfls = [\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak10_Melbourne_klaar_Sheet1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak11_Melbourne_klaar_Sheet1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak12_Melbourne_klaar_Sheet1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak13_Melbourne_klaar_Sheet1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak1_Brisbane_klaar_Blad1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak27_nw_south_wales_klaar_bak_nw_south_wales_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak28_Queensland_klaar_Bak_28_Queensland_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak29_Sydney_klaar_bak_29_Sydney_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak2_Brisbane_klaar_Blad1_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak30_Sydney_klaar_Bak_30_Sydney_out.csv handled\",\n",
    "\"/Users/rikhoekstra/surfdrive/emigratie/emigrantenkaarten/database/bakken_geordend/csv/bak31_Sydney_klaar_Blad1_out.csv handled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodecsv import DictReader\n",
    "imfls = [fl for fl in imfls if fl not in outfls]\n",
    "faulty_items = []\n",
    "for fn in imfls:\n",
    "    try:\n",
    "        flin = open(fn)\n",
    "        r = DictReader(flin)\n",
    "        ims = [row for row in r]\n",
    "        for row in ims:\n",
    "            row['parent'] = row['kaart']\n",
    "            row['aantekening'] = row['aantekening']\n",
    "            edocr = getedges(imagetemplate.format( map=int(row['bak']), imnr=int(row[\"image\"])))\n",
    "            row['id'] = \"{map}_{imnr:04d}\".format(map=row['bak'], imnr=int(row['image']))\n",
    "            row['url'] = urltemplate.format(url=url, map=int(row['bak']), imnr=int(row[\"image\"]))\n",
    "            row['edges'] = int(edocr['edge'])\n",
    "            row['locr'] = int(edocr['locr'])\n",
    "            row['ocr'] = dammit(edocr['ocr']).unicode_markup\n",
    "        \n",
    "    except IndexError, KeyError:\n",
    "        faulty_items.append(row)\n",
    "    data_dict = ims\n",
    "    bulk_data = []\n",
    "    for item in data_dict:\n",
    "        try:\n",
    "            bulk_data.append({'index':{'_type':'image', \n",
    "                                       '_index':index,\n",
    "                                       'parent': item['parent'],\n",
    "                                       '_id':'%s' % item['id']}})\n",
    "            bulk_data.append(item)\n",
    "        except KeyError:\n",
    "            print fn\n",
    "            print item\n",
    "\n",
    "    index = \"migrants\"\n",
    "    es.bulk(index=index, body=bulk_data, refresh=True)\n",
    "    outfls.append(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5255c8d7ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_migrant\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbulk_data_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'es_ims_bulk.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbulk_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_data_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbulk_data_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbulk_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "bulk_data_file = open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
